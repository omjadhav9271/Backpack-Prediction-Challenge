{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omjad\\AppData\\Local\\Temp\\ipykernel_20368\\220310148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\omjad\\AppData\\Local\\Temp\\ipykernel_20368\\220310148.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\omjad\\AppData\\Local\\Temp\\ipykernel_20368\\220310148.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\omjad\\AppData\\Local\\Temp\\ipykernel_20368\\220310148.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(mode_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE: 39.0204 ± 0.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.448481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.385450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.350366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.448324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.422913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Resume Projects\\Backpack Prediction Challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM        RMSE: 39.0516 ± 0.0561\n",
      "XGBoost         RMSE: 39.0673 ± 0.0550\n",
      "NeuralNetwork   RMSE: 39.0461 ± 0.0568\n",
      "\n",
      "Best model: LinearRegression\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Preprocessing for binary columns\n",
    "binary_cols = ['Laptop Compartment', 'Waterproof']\n",
    "for col in binary_cols:\n",
    "    mode_val = train[col].mode()[0]\n",
    "    train[col].fillna(mode_val, inplace=True)\n",
    "    test[col].fillna(mode_val, inplace=True)\n",
    "    train[col] = train[col].map({'Yes': 1, 'No': 0}).astype(int)\n",
    "    test[col] = test[col].map({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "# Standardize categorical columns\n",
    "categorical_cols = ['Brand', 'Material', 'Size', 'Style', 'Color']\n",
    "for col in categorical_cols:\n",
    "    train[col] = train[col].str.strip().str.lower()\n",
    "    test[col] = test[col].str.strip().str.lower()\n",
    "\n",
    "# Prepare data\n",
    "X_train = train.drop(['id', 'Price'], axis=1)\n",
    "y_train = train['Price']\n",
    "X_test = test.drop('id', axis=1)\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "num_features = ['Compartments', 'Weight Capacity (kg)'] + binary_cols\n",
    "cat_features = categorical_cols\n",
    "\n",
    "# Preprocessor for linear models and neural networks\n",
    "preprocessor_linear = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_features)\n",
    "])\n",
    "\n",
    "# Preprocessor for tree-based models\n",
    "preprocessor_tree = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='mean'), num_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ]), cat_features)\n",
    "])\n",
    "\n",
    "# Define models with hyperparameters\n",
    "models = {\n",
    "    'LinearRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor_linear),\n",
    "        ('model', LinearRegression())\n",
    "    ]),\n",
    "    'LightGBM': Pipeline([\n",
    "        ('preprocessor', preprocessor_tree),\n",
    "        ('model', lgb.LGBMRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=32,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('preprocessor', preprocessor_tree),\n",
    "        ('model', xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    'NeuralNetwork': Pipeline([\n",
    "        ('preprocessor', preprocessor_linear),\n",
    "        ('model', MLPRegressor(\n",
    "            hidden_layer_sizes=(128, 64),\n",
    "            early_stopping=True,\n",
    "            random_state=42,\n",
    "            max_iter=500\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Evaluate models using cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scorer = make_scorer(lambda y, y_pred: np.sqrt(np.mean((y - y_pred)**2)))\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=rmse_scorer)\n",
    "    results[name] = np.mean(scores)\n",
    "    print(f\"{name:15} RMSE: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "\n",
    "# Train final model\n",
    "best_model = models[best_model_name].fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Price': predictions.round(3)\n",
    "})\n",
    "submission.to_csv('mix_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
